{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 0. Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from vae import VAE\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Set up pathing options (NB only works for Colab or Paperspace)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (8.0.5)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipywidgets) (8.11.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipywidgets) (3.0.6)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipywidgets) (4.0.6)\r\n",
      "Requirement already satisfied: appnope in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\r\n",
      "Requirement already satisfied: decorator in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: backcall in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: pickleshare in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\r\n",
      "Requirement already satisfied: stack-data in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six in /Users/ludovicobuizza/code/2023_projects/medium/venv/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\r\n",
      "You should consider upgrading via the '/Users/ludovicobuizza/code/2023_projects/medium/venv/bin/python3.10 -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "WORKING_ENV = 'PAPERSPACE'\n",
    "assert WORKING_ENV in ['LABS', 'COLAB', 'PAPERSPACE']\n",
    "\n",
    "if WORKING_ENV == 'COLAB':\n",
    "    from google.colab import drive\n",
    "    %load_ext google.colab.data_table\n",
    "    content_path = '/content/drive/MyDrive/vae'\n",
    "    data_path = './data/'\n",
    "    drive.mount('/content/drive/')\n",
    "\n",
    "else:\n",
    "    !pip install ipywidgets\n",
    "    content_path = '/notebooks'\n",
    "    data_path = './data/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***More set up***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/notebooks'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m     plt\u001B[38;5;241m.\u001B[39mimshow(np\u001B[38;5;241m.\u001B[39mtranspose(npimg, (\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m0\u001B[39m)))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(content_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/VAE/\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m----> 6\u001B[0m     \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/VAE/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(data_path):\n\u001B[1;32m      9\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(data_path)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:225\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 225\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001B[39;00m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exist_ok \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39misdir(name):\n",
      "\u001B[0;31mOSError\u001B[0m: [Errno 30] Read-only file system: '/notebooks'"
     ]
    }
   ],
   "source": [
    "def show(img):\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "if not os.path.exists(content_path + '/VAE/'):\n",
    "    os.makedirs(content_path + '/VAE/')\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "# Set a random seed to ensure that results are reproducible.\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(0)\n",
    "\n",
    "GPU = True\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Using {device}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "train_dat = datasets.MNIST(\n",
    "    data_path, train=True, download=True, transform=transform\n",
    ")\n",
    "test_dat = datasets.MNIST(data_path, train=False, transform=transform)\n",
    "\n",
    "loader_train = DataLoader(train_dat, batch_size, shuffle=True)\n",
    "loader_test = DataLoader(test_dat, batch_size, shuffle=False)\n",
    "\n",
    "# Don't change\n",
    "sample_inputs, _ = next(iter(loader_test))\n",
    "fixed_input = sample_inputs[:32, :, :, :]\n",
    "save_image(fixed_input, content_path + '/VAE/image_original.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Set hyperparameters for the encoder and decoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dims = 12\n",
    "encoder_hyper_params = {\n",
    "    \"latent_dims\": latent_dims,\n",
    "    \"hidden_channels\": [24, 24, 24, 24],\n",
    "    \"kernels\": [3, 3, 3, 3],\n",
    "    \"strides\": [1, 2, 2, 1],\n",
    "    \"paddings\": [1, 1, 1, 1],\n",
    "    \"in_channels\": 1,\n",
    "    \"fc_neurons\": 24 * 49\n",
    "}\n",
    "\n",
    "decoder_hyper_params = {\n",
    "    \"in_channels\": 24,\n",
    "    \"hidden_channels\": [24, 24, 24, 6],\n",
    "    \"kernels\": [3, 4, 4, 4],\n",
    "    \"strides\": [1, 2, 2, 1],\n",
    "    \"paddings\": [0, 0, 0, 0],\n",
    "    \"out_channels\": 1,\n",
    "    \"final_kernel\": 4,\n",
    "    \"final_stride\": 1,\n",
    "    \"final_padding\": 0,\n",
    "    \"final_output_padding\": 0\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Set hyperparameters for the learning process***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learning_rate = 5E-4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Train the VAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Define the loss function***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def loss_function_VAE(recon_x, x, mu, logvar, beta):\n",
    "    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum') # Sigmoid\n",
    "    kl_divergence = - 0.5 * (1 + logvar - mu.pow(2) - logvar.exp()).sum()\n",
    "    loss = recon_loss + beta*kl_divergence\n",
    "    return loss, recon_loss, kl_divergence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Store results***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plots = []\n",
    "betas = [0, 0.1, 1, 3, 5, 10, 100]\n",
    "models = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Training loop***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def step(data, training=True):\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    recon_x, x, mu, logvar = model(data)\n",
    "    loss, bce_loss, kld_loss = loss_function_VAE(recon_x, x, mu, logvar, beta)\n",
    "    if training:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss, kld_loss, bce_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = VAE(encoder_hyper_params=encoder_hyper_params,\n",
    "            decoder_hyper_params=decoder_hyper_params)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for beta in betas:\n",
    "    plotting_dict = {\n",
    "    \"train_total_loss\": [],\n",
    "    \"train_KLD\": [],\n",
    "    \"train_bce\": [],\n",
    "    \"test_total_loss\": [],\n",
    "    \"test_KLD\": [],\n",
    "    \"test_bce\": [],\n",
    "    }\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss_mean = 0\n",
    "        kld_mean = 0\n",
    "        bce_mean = 0\n",
    "        model.train()\n",
    "        with tqdm.tqdm(loader_train, unit=\"batch\") as tepoch:\n",
    "            for batch_idx, (data, _) in enumerate(tepoch):\n",
    "                loss, kld_loss, bce_loss = step(data)\n",
    "                total_loss_mean += loss.detach().item()\n",
    "                kld_mean += kld_loss.detach().item()\n",
    "                bce_mean += bce_loss.detach().item()\n",
    "                if batch_idx % 20 == 0:\n",
    "                    tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                    tepoch.set_postfix(loss=loss.item()/len(data))\n",
    "\n",
    "        plotting_dict[\"train_total_loss\"].append(total_loss_mean/len(loader_train))\n",
    "        plotting_dict[\"train_bce\"].append(bce_mean/len(loader_train))\n",
    "        plotting_dict[\"train_KLD\"].append(kld_mean/len(loader_train))\n",
    "\n",
    "        total_loss_mean = 0\n",
    "        kld_mean = 0\n",
    "        bce_mean = 0\n",
    "        model.eval()\n",
    "\n",
    "        for batch_idx, (data, _) in enumerate(loader_test):\n",
    "            loss, kld_loss, bce_loss = step(data, training=False)\n",
    "            total_loss_mean += loss.detach().item()\n",
    "            kld_mean += kld_loss.detach().item()\n",
    "            bce_mean += bce_loss.detach().item()\n",
    "\n",
    "        plotting_dict[\"test_total_loss\"].append(total_loss_mean/len(loader_test))\n",
    "        plotting_dict[\"test_bce\"].append(bce_mean/len(loader_test))\n",
    "        plotting_dict[\"test_KLD\"].append(kld_mean/len(loader_test))\n",
    "        #######\n",
    "\n",
    "\n",
    "        # save the model\n",
    "        if epoch == num_epochs - 1 and beta == 3:\n",
    "            with torch.no_grad():\n",
    "                torch.jit.save(torch.jit.trace(model, (data), check_trace=False),\n",
    "                    content_path/f'VAE/VAE_model_beta={beta}.pth')\n",
    "    plots.append(plotting_dict)\n",
    "    models.append(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Samples from the VAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Input images')\n",
    "print('-'*50)\n",
    "for i, model in enumerate(models):\n",
    "    sample_inputs, _ = next(iter(loader_test))\n",
    "    fixed_input = sample_inputs[0:32, :, :, :]\n",
    "    # visualize the original images of the last batch of the test set\n",
    "    img = make_grid(fixed_input, nrow=8, padding=2, normalize=False,\n",
    "                    range=None, scale_each=False, pad_value=0)\n",
    "    plt.figure()\n",
    "    show(img)\n",
    "    print(f'*** BETA = {betas[i]} ***')\n",
    "    print('Reconstructed images')\n",
    "    print('-'*50)\n",
    "    with torch.no_grad():\n",
    "        fixed_input = fixed_input.to(device)\n",
    "        recon_batch, _, _, _ = model(fixed_input)\n",
    "        recon_batch = recon_batch.cpu()\n",
    "        recon_batch = make_grid(recon_batch, nrow=8, padding=2, normalize=False,\n",
    "                                range=None, scale_each=False, pad_value=0)\n",
    "        plt.figure()\n",
    "        show(recon_batch)\n",
    "\n",
    "    print('Generated Images')\n",
    "    print('-'*50)\n",
    "    model.eval()\n",
    "    n_samples = 256\n",
    "    z = torch.randn(n_samples,latent_dims).to(device)\n",
    "    with torch.no_grad():\n",
    "        samples = model.decode(z)\n",
    "        samples = samples.cpu()\n",
    "        samples = make_grid(samples, nrow=16, padding=2, normalize=False,\n",
    "                                range=None, scale_each=False, pad_value=0)\n",
    "        plt.figure(figsize = (8,8))\n",
    "        show(samples)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
